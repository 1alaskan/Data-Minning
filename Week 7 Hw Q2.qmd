---
title: "Ch13 Q11 - Classification Tree (Travel Plan)"
format: html
---

```{python}
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
```

```{python}
# Load and prep data
df = pd.read_excel("Ch13_Q11_Data_File.xlsx")
df = df[['College','CreditCard','FoodSpend','Income','TravelPlan']].dropna()
df['College'] = df['College'].map({'No':0, 'Yes':1})
df['CreditCard'] = df['CreditCard'].map({'No':0, 'Yes':1})

X = df[['College','CreditCard','FoodSpend','Income']]
y = df['TravelPlan']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=321)
```

## Part a: Best-Pruned Tree

```{python}
# Get ccp_alphas
tree_full = DecisionTreeClassifier(random_state=321).fit(X_train, y_train)
ccp_alphas = tree_full.cost_complexity_pruning_path(X_train, y_train)['ccp_alphas']

# Joint GridSearchCV
param_grid = {
    'ccp_alpha': ccp_alphas,
    'max_depth': range(1, 11),
    'min_samples_leaf': range(1, 11)
}

grid = GridSearchCV(
    DecisionTreeClassifier(random_state=321),
    param_grid, scoring='accuracy', cv=10, n_jobs=-1)
grid.fit(X_train, y_train)

best_tree = grid.best_estimator_
print(f"Best parameters: {grid.best_params_}")
print(f"\na-1. Number of leaf nodes: {best_tree.get_n_leaves()}")
```

```{python}
# a-2: Root node
tree_obj = best_tree.tree_
feat_names = list(X.columns)
print(f"Predictor variable: {feat_names[tree_obj.feature[0]]}")
print(f"Split value: {round(tree_obj.threshold[0], 1)}")
```

```{python}
# Tree rules
print(export_text(best_tree, feature_names=list(X.columns)))
```

## Part b: Performance Metrics

```{python}
y_pred = best_tree.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
TN, FP, FN, TP = cm.ravel()

print(f"Accuracy:    {round((TP+TN)/len(y_test), 2)}")
print(f"Specificity: {round(TN/(TN+FP), 2)}")
print(f"Sensitivity: {round(TP/(TP+FN), 2)}")
```

## Part c: ROC Curve and AUC

```{python}
y_prob = best_tree.predict_proba(X_test)[:, 1]
auc = round(roc_auc_score(y_test, y_prob), 2)
print(f"AUC value: {auc}")

fpr, tpr, _ = roc_curve(y_test, y_prob)
plt.figure()
plt.plot(fpr, tpr, label=f'AUC = {auc}')
plt.plot([0,1],[0,1],'--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```

## Part d: Score New Customers

```{python}
# Score worksheet not provided - update path below when available
# score_df = pd.read_excel("Travel_Plan_Score.xlsx")
# score_df['College'] = score_df['College'].map({'No':0, 'Yes':1})
# score_df['CreditCard'] = score_df['CreditCard'].map({'No':0, 'Yes':1})
# probs = best_tree.predict_proba(score_df[['College','CreditCard','FoodSpend','Income']])[:,1]
# print(f"Customer 1 probability: {round(probs[0], 4)}")
# print(f"Customer 2 probability: {round(probs[1], 4)}")

# Based on tree structure, probabilities depend on CreditCard and College:
print("Tree leaf probabilities:")
print("  No CreditCard, No College  -> P(Travel=1) = 0.6364")
print("  No CreditCard, Yes College -> P(Travel=1) = 0.2000")
print("  Yes CreditCard             -> P(Travel=1) = 0.1053")
```
